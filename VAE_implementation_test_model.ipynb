{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-jwuBfWplDZB",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import imageio\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import norm\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend\n",
    "from keras import layers, Input, Model, ops\n",
    "\n",
    "import seaborn as sns\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7BCnAMU5lDZE"
   },
   "source": [
    "We take the pickle file (`.pkl`) containing the images (in this workbook, from the A1 tile) and the `csv` file containing the redshifts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "C5b2oeynlDZE",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# if you make pickle files from the data generator\n",
    "# DATA_PATH = \"pickles/A1_compiled_cutouts_3arcsec_30mas.pkl\"\n",
    "\n",
    "# if you download directly from the drive\n",
    "DATA_PATH = \"A1_compiled_cutouts_3arcsec_30mas.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "2xlVRoiUlDZF",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "# rows: ID, image info\n",
    "with open(DATA_PATH, \"rb\") as f:\n",
    "    data = pickle.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDs\n",
    "ids = data[0]\n",
    "\n",
    "# images\n",
    "images = np.stack(data[1]).astype(\"float32\")\n",
    "images = np.log10(images - np.min(images)+0.007) # log transform to reduce differences in scale\n",
    "images = images / np.max(images)  # normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oczGWx9mlDZG"
   },
   "source": [
    "Match and merge the datasets based on the object's ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "wmBIzomnlDZH"
   },
   "outputs": [],
   "source": [
    "attrs = pd.read_csv(\"cosmos_cut.csv\", sep=\",\")\n",
    "\n",
    "df_images = pd.DataFrame({'id': ids}) # from ID numbers\n",
    "df_merged = pd.merge(df_images, attrs, on=\"id\", how=\"inner\") # only when IDs match\n",
    "\n",
    "images = images[df_merged.index]\n",
    "redshifts = df_merged[\"z\"].to_numpy(dtype=\"float32\")\n",
    "redshifts = redshifts / np.max(redshifts) # normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augment data to extend AGN and LRD parts of the database so that the dataset is more balanced:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original size: 4512\n",
      "Augmented size: 4820\n"
     ]
    }
   ],
   "source": [
    "classes = df_merged[\"classification\"].to_numpy()\n",
    "obj_ids = df_merged[\"id\"].to_numpy()\n",
    "\n",
    "aug_images = []\n",
    "aug_ids = []\n",
    "aug_redshifts = []\n",
    "\n",
    "for img, obj_id, z, cls in zip(images, obj_ids, redshifts, classes):\n",
    "    if cls == \"Galaxy\":\n",
    "        # keep as-is, no augmentation\n",
    "        aug_images.append(img)\n",
    "        aug_ids.append(obj_id)\n",
    "        aug_redshifts.append(z)\n",
    "\n",
    "    elif cls == \"AGN\":\n",
    "        # rotations -> 4 total (0°, 90°, 180°, 270°)\n",
    "        variants = [\n",
    "            img,\n",
    "            np.rot90(img, 1, axes=(0, 1)),\n",
    "            np.rot90(img, 2, axes=(0, 1)),\n",
    "            np.rot90(img, 3, axes=(0, 1)),\n",
    "        ]\n",
    "        for v in variants:\n",
    "            aug_images.append(v)\n",
    "            aug_ids.append(obj_id)\n",
    "            aug_redshifts.append(z)\n",
    "\n",
    "    elif cls == \"LRD\":\n",
    "        # rotations + flips (more aggressive augmentation)\n",
    "        base_rots = [\n",
    "            img,\n",
    "            np.rot90(img, 1, axes=(0, 1)),\n",
    "            np.rot90(img, 2, axes=(0, 1)),\n",
    "            np.rot90(img, 3, axes=(0, 1)),\n",
    "        ]\n",
    "        variants = base_rots + [\n",
    "            np.fliplr(img),\n",
    "            np.flipud(img),\n",
    "            np.fliplr(base_rots[1]),  # flipped 90°\n",
    "            np.flipud(base_rots[1]),  # flipped 90°\n",
    "        ]\n",
    "        for v in variants:\n",
    "            aug_images.append(v)\n",
    "            aug_ids.append(obj_id)\n",
    "            aug_redshifts.append(z)\n",
    "\n",
    "    else:\n",
    "        # any other class: just keep original\n",
    "        aug_images.append(img)\n",
    "        aug_ids.append(obj_id)\n",
    "        aug_redshifts.append(z)\n",
    "\n",
    "# -------------------------\n",
    "# final augmented datasets\n",
    "# -------------------------\n",
    "aug_images = np.stack(aug_images).astype(\"float32\")\n",
    "aug_ids = np.array(aug_ids)\n",
    "aug_redshifts = np.array(aug_redshifts, dtype=\"float32\")\n",
    "\n",
    "print(\"Original size:\", len(images))\n",
    "print(\"Augmented size:\", len(aug_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expand metadata to include augmented samples\n",
    "# takes all instances of an ID\n",
    "df_aug = pd.DataFrame({\"id\": aug_ids})\n",
    "df_aug = df_aug.merge(df_merged, on=\"id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y_g1T8-JlDZJ"
   },
   "source": [
    "# Load the pre-trained autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom sampling layer\n",
    "class Sampling(layers.Layer):\n",
    "    def __init__(self, beta=1.0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.beta = beta\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.rng = keras.random.SeedGenerator(1337)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        mean, logvar = inputs\n",
    "        eps = keras.random.normal(\n",
    "            shape=ops.shape(mean),\n",
    "            dtype=mean.dtype,\n",
    "            seed=self.rng\n",
    "        )\n",
    "        z = mean + ops.exp(0.5 * logvar) * eps\n",
    "\n",
    "        kl = -0.5 * ops.sum(\n",
    "            1 + logvar - ops.square(mean) - ops.exp(logvar),\n",
    "            axis=-1\n",
    "        )\n",
    "        self.add_loss(self.beta * ops.mean(kl))\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "<class 'keras.src.models.functional.Functional'> could not be deserialized properly. Please ensure that components that are Python object instances (layers, models, etc.) returned by `get_config()` are explicitly deserialized in the model's `from_config()` method.\n\nconfig={'module': 'keras.src.models.functional', 'class_name': 'Functional', 'config': {}, 'registered_name': 'Functional', 'build_config': {'input_shape': None}, 'compile_config': {'optimizer': {'module': 'keras.optimizers', 'class_name': 'Adam', 'config': {'name': 'adam', 'learning_rate': 0.0010000000474974513, 'weight_decay': None, 'clipnorm': None, 'global_clipnorm': None, 'clipvalue': None, 'use_ema': False, 'ema_momentum': 0.99, 'ema_overwrite_frequency': None, 'loss_scale_factor': None, 'gradient_accumulation_steps': None, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}, 'registered_name': None}, 'loss': {'image_recon': 'mse', 'z_recon': 'mse'}, 'loss_weights': {'image_recon': 1000.0, 'z_recon': 1.0}, 'metrics': None, 'weighted_metrics': None, 'run_eagerly': False, 'steps_per_execution': 1, 'jit_compile': True}}.\n\nException encountered: <class 'keras.src.layers.preprocessing.image_preprocessing.resizing.Resizing'> could not be deserialized properly. Please ensure that components that are Python object instances (layers, models, etc.) returned by `get_config()` are explicitly deserialized in the model's `from_config()` method.\n\nconfig={'module': 'keras.layers', 'class_name': 'Resizing', 'config': {'name': 'resizing_1', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 138503526256416}, 'height': 100, 'width': 100, 'interpolation': 'bilinear', 'crop_to_aspect_ratio': False, 'pad_to_aspect_ratio': False, 'fill_mode': 'constant', 'fill_value': 0.0, 'antialias': False, 'data_format': 'channels_last'}, 'registered_name': None, 'build_config': {'input_shape': [None, 96, 96, 32]}, 'name': 'resizing_1', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 96, 96, 32], 'dtype': 'float32', 'keras_history': ['conv2d_11', 0, 0]}}], 'kwargs': {'training': True}}]}.\n\nException encountered: Error when deserializing class 'Resizing' using config={'name': 'resizing_1', 'trainable': True, 'dtype': 'float32', 'height': 100, 'width': 100, 'interpolation': 'bilinear', 'crop_to_aspect_ratio': False, 'pad_to_aspect_ratio': False, 'fill_mode': 'constant', 'fill_value': 0.0, 'antialias': False, 'data_format': 'channels_last'}.\n\nException encountered: Unrecognized keyword arguments passed to Resizing: {'antialias': False}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/keras/src/ops/operation.py:234\u001b[0m, in \u001b[0;36mOperation.from_config\u001b[0;34m(cls, config)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig)\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/preprocessing/image_preprocessing/resizing.py:85\u001b[0m, in \u001b[0;36mResizing.__init__\u001b[0;34m(self, height, width, interpolation, crop_to_aspect_ratio, pad_to_aspect_ratio, fill_mode, fill_value, data_format, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     75\u001b[0m     height,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m     84\u001b[0m ):\n\u001b[0;32m---> 85\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheight \u001b[38;5;241m=\u001b[39m height\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/preprocessing/image_preprocessing/base_image_preprocessing_layer.py:15\u001b[0m, in \u001b[0;36mBaseImagePreprocessingLayer.__init__\u001b[0;34m(self, factor, bounding_box_format, data_format, **kwargs)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mself\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, bounding_box_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, data_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m     14\u001b[0m ):\n\u001b[0;32m---> 15\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbounding_box_format \u001b[38;5;241m=\u001b[39m bounding_box_format\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/preprocessing/tf_data_layer.py:19\u001b[0m, in \u001b[0;36mTFDataLayer.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 19\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend \u001b[38;5;241m=\u001b[39m backend_utils\u001b[38;5;241m.\u001b[39mDynamicBackend()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/layer.py:285\u001b[0m, in \u001b[0;36mLayer.__init__\u001b[0;34m(self, activity_regularizer, trainable, dtype, autocast, name, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[0;32m--> 285\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    286\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized keyword arguments \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    287\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassed to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    288\u001b[0m     )\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# Will be determined in `build_wrapper`\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Unrecognized keyword arguments passed to Resizing: {'antialias': False}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/keras/src/saving/serialization_lib.py:718\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    717\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 718\u001b[0m     instance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_config(inner_config)\n\u001b[1;32m    719\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/keras/src/ops/operation.py:236\u001b[0m, in \u001b[0;36mOperation.from_config\u001b[0;34m(cls, config)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 236\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    237\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError when deserializing class \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m using \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    238\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mException encountered: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    239\u001b[0m     )\n",
      "\u001b[0;31mTypeError\u001b[0m: Error when deserializing class 'Resizing' using config={'name': 'resizing_1', 'trainable': True, 'dtype': 'float32', 'height': 100, 'width': 100, 'interpolation': 'bilinear', 'crop_to_aspect_ratio': False, 'pad_to_aspect_ratio': False, 'fill_mode': 'constant', 'fill_value': 0.0, 'antialias': False, 'data_format': 'channels_last'}.\n\nException encountered: Unrecognized keyword arguments passed to Resizing: {'antialias': False}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/keras/src/saving/serialization_lib.py:718\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    717\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 718\u001b[0m     instance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_config(inner_config)\n\u001b[1;32m    719\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/keras/src/models/model.py:527\u001b[0m, in \u001b[0;36mModel.from_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m    525\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m functional_from_config\n\u001b[0;32m--> 527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m functional_from_config(\n\u001b[1;32m    528\u001b[0m         \u001b[38;5;28mcls\u001b[39m, config, custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects\n\u001b[1;32m    529\u001b[0m     )\n\u001b[1;32m    531\u001b[0m \u001b[38;5;66;03m# Either the model has a custom __init__, or the config\u001b[39;00m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;66;03m# does not contain all the information necessary to\u001b[39;00m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;66;03m# revive a Functional model. This happens when the user creates\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;66;03m# In this case, we fall back to provide all config into the\u001b[39;00m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;66;03m# constructor of the class.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/keras/src/models/functional.py:546\u001b[0m, in \u001b[0;36mfunctional_from_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer_data \u001b[38;5;129;01min\u001b[39;00m functional_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayers\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 546\u001b[0m     process_layer(layer_data)\n\u001b[1;32m    548\u001b[0m \u001b[38;5;66;03m# Then we process nodes in order of layer depth.\u001b[39;00m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;66;03m# Nodes that cannot yet be processed (if the inbound node\u001b[39;00m\n\u001b[1;32m    550\u001b[0m \u001b[38;5;66;03m# does not yet exist) are re-enqueued, and the process\u001b[39;00m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;66;03m# is repeated until all nodes are processed.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/keras/src/models/functional.py:518\u001b[0m, in \u001b[0;36mfunctional_from_config.<locals>.process_layer\u001b[0;34m(layer_data)\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 518\u001b[0m     layer \u001b[38;5;241m=\u001b[39m serialization_lib\u001b[38;5;241m.\u001b[39mdeserialize_keras_object(\n\u001b[1;32m    519\u001b[0m         layer_data, custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects\n\u001b[1;32m    520\u001b[0m     )\n\u001b[1;32m    521\u001b[0m created_layers[layer_name] \u001b[38;5;241m=\u001b[39m layer\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/keras/src/saving/serialization_lib.py:720\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 720\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    721\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m could not be deserialized properly. Please\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    722\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m ensure that components that are Python object\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    723\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m instances (layers, models, etc.) returned by\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    724\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `get_config()` are explicitly deserialized in the\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    725\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m model\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms `from_config()` method.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    726\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mconfig=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mException encountered: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    727\u001b[0m     )\n\u001b[1;32m    728\u001b[0m build_config \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuild_config\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: <class 'keras.src.layers.preprocessing.image_preprocessing.resizing.Resizing'> could not be deserialized properly. Please ensure that components that are Python object instances (layers, models, etc.) returned by `get_config()` are explicitly deserialized in the model's `from_config()` method.\n\nconfig={'module': 'keras.layers', 'class_name': 'Resizing', 'config': {'name': 'resizing_1', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 138503526256416}, 'height': 100, 'width': 100, 'interpolation': 'bilinear', 'crop_to_aspect_ratio': False, 'pad_to_aspect_ratio': False, 'fill_mode': 'constant', 'fill_value': 0.0, 'antialias': False, 'data_format': 'channels_last'}, 'registered_name': None, 'build_config': {'input_shape': [None, 96, 96, 32]}, 'name': 'resizing_1', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 96, 96, 32], 'dtype': 'float32', 'keras_history': ['conv2d_11', 0, 0]}}], 'kwargs': {'training': True}}]}.\n\nException encountered: Error when deserializing class 'Resizing' using config={'name': 'resizing_1', 'trainable': True, 'dtype': 'float32', 'height': 100, 'width': 100, 'interpolation': 'bilinear', 'crop_to_aspect_ratio': False, 'pad_to_aspect_ratio': False, 'fill_mode': 'constant', 'fill_value': 0.0, 'antialias': False, 'data_format': 'channels_last'}.\n\nException encountered: Unrecognized keyword arguments passed to Resizing: {'antialias': False}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m autoencoder \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest1_autoencoder.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     custom_objects\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSampling\u001b[39m\u001b[38;5;124m\"\u001b[39m: Sampling})\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/keras/src/saving/saving_api.py:189\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    186\u001b[0m         is_keras_zip \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_keras_zip \u001b[38;5;129;01mor\u001b[39;00m is_keras_dir \u001b[38;5;129;01mor\u001b[39;00m is_hf:\n\u001b[0;32m--> 189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[1;32m    190\u001b[0m         filepath,\n\u001b[1;32m    191\u001b[0m         custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[1;32m    192\u001b[0m         \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m,\n\u001b[1;32m    193\u001b[0m         safe_mode\u001b[38;5;241m=\u001b[39msafe_mode,\n\u001b[1;32m    194\u001b[0m     )\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m legacy_h5_format\u001b[38;5;241m.\u001b[39mload_model_from_hdf5(\n\u001b[1;32m    197\u001b[0m         filepath, custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects, \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m\n\u001b[1;32m    198\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:367\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    363\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid filename: expected a `.keras` extension. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    364\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    365\u001b[0m     )\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filepath, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m--> 367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _load_model_from_fileobj(\n\u001b[1;32m    368\u001b[0m         f, custom_objects, \u001b[38;5;28mcompile\u001b[39m, safe_mode\n\u001b[1;32m    369\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:444\u001b[0m, in \u001b[0;36m_load_model_from_fileobj\u001b[0;34m(fileobj, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m zf\u001b[38;5;241m.\u001b[39mopen(_CONFIG_FILENAME, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    442\u001b[0m     config_json \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m--> 444\u001b[0m model \u001b[38;5;241m=\u001b[39m _model_from_config(\n\u001b[1;32m    445\u001b[0m     config_json, custom_objects, \u001b[38;5;28mcompile\u001b[39m, safe_mode\n\u001b[1;32m    446\u001b[0m )\n\u001b[1;32m    448\u001b[0m all_filenames \u001b[38;5;241m=\u001b[39m zf\u001b[38;5;241m.\u001b[39mnamelist()\n\u001b[1;32m    449\u001b[0m extract_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:433\u001b[0m, in \u001b[0;36m_model_from_config\u001b[0;34m(config_json, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;66;03m# Construct the model from the configuration file in the archive.\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ObjectSharingScope():\n\u001b[0;32m--> 433\u001b[0m     model \u001b[38;5;241m=\u001b[39m deserialize_keras_object(\n\u001b[1;32m    434\u001b[0m         config_dict, custom_objects, safe_mode\u001b[38;5;241m=\u001b[39msafe_mode\n\u001b[1;32m    435\u001b[0m     )\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/keras/src/saving/serialization_lib.py:720\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    718\u001b[0m     instance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_config(inner_config)\n\u001b[1;32m    719\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 720\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    721\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m could not be deserialized properly. Please\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    722\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m ensure that components that are Python object\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    723\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m instances (layers, models, etc.) returned by\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    724\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `get_config()` are explicitly deserialized in the\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    725\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m model\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms `from_config()` method.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    726\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mconfig=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mException encountered: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    727\u001b[0m     )\n\u001b[1;32m    728\u001b[0m build_config \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuild_config\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    729\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m build_config \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m instance\u001b[38;5;241m.\u001b[39mbuilt:\n",
      "\u001b[0;31mTypeError\u001b[0m: <class 'keras.src.models.functional.Functional'> could not be deserialized properly. Please ensure that components that are Python object instances (layers, models, etc.) returned by `get_config()` are explicitly deserialized in the model's `from_config()` method.\n\nconfig={'module': 'keras.src.models.functional', 'class_name': 'Functional', 'config': {}, 'registered_name': 'Functional', 'build_config': {'input_shape': None}, 'compile_config': {'optimizer': {'module': 'keras.optimizers', 'class_name': 'Adam', 'config': {'name': 'adam', 'learning_rate': 0.0010000000474974513, 'weight_decay': None, 'clipnorm': None, 'global_clipnorm': None, 'clipvalue': None, 'use_ema': False, 'ema_momentum': 0.99, 'ema_overwrite_frequency': None, 'loss_scale_factor': None, 'gradient_accumulation_steps': None, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}, 'registered_name': None}, 'loss': {'image_recon': 'mse', 'z_recon': 'mse'}, 'loss_weights': {'image_recon': 1000.0, 'z_recon': 1.0}, 'metrics': None, 'weighted_metrics': None, 'run_eagerly': False, 'steps_per_execution': 1, 'jit_compile': True}}.\n\nException encountered: <class 'keras.src.layers.preprocessing.image_preprocessing.resizing.Resizing'> could not be deserialized properly. Please ensure that components that are Python object instances (layers, models, etc.) returned by `get_config()` are explicitly deserialized in the model's `from_config()` method.\n\nconfig={'module': 'keras.layers', 'class_name': 'Resizing', 'config': {'name': 'resizing_1', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 138503526256416}, 'height': 100, 'width': 100, 'interpolation': 'bilinear', 'crop_to_aspect_ratio': False, 'pad_to_aspect_ratio': False, 'fill_mode': 'constant', 'fill_value': 0.0, 'antialias': False, 'data_format': 'channels_last'}, 'registered_name': None, 'build_config': {'input_shape': [None, 96, 96, 32]}, 'name': 'resizing_1', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 96, 96, 32], 'dtype': 'float32', 'keras_history': ['conv2d_11', 0, 0]}}], 'kwargs': {'training': True}}]}.\n\nException encountered: Error when deserializing class 'Resizing' using config={'name': 'resizing_1', 'trainable': True, 'dtype': 'float32', 'height': 100, 'width': 100, 'interpolation': 'bilinear', 'crop_to_aspect_ratio': False, 'pad_to_aspect_ratio': False, 'fill_mode': 'constant', 'fill_value': 0.0, 'antialias': False, 'data_format': 'channels_last'}.\n\nException encountered: Unrecognized keyword arguments passed to Resizing: {'antialias': False}"
     ]
    }
   ],
   "source": [
    "autoencoder = keras.models.load_model(\n",
    "    \"test1_autoencoder.keras\",\n",
    "    custom_objects={\"Sampling\": Sampling})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training and validation sets\n",
    "X_train, X_val, z_train, z_val = train_test_split(aug_images, aug_redshifts, test_size=0.2, random_state=42)\n",
    "\n",
    "z_train = z_train.reshape(-1, 1)\n",
    "z_val = z_val.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def _asinh_stretch(x, scale=None):\n",
    "    \"\"\"\n",
    "    Asinh stretch commonly used for astro images.\n",
    "    If scale is None, use a robust estimate based on the 90th percentile of |x|.\n",
    "    \"\"\"\n",
    "    x = np.asarray(x)\n",
    "    if scale is None:\n",
    "        p = np.nanpercentile(np.abs(x), 90)\n",
    "        scale = p if p > 0 else np.nanmax(np.abs(x)) + 1e-8\n",
    "    return np.arcsinh(x / (scale + 1e-12))\n",
    "\n",
    "def _auto_vmin_vmax(x, pct=(1, 99)):\n",
    "    \"\"\"Robust display limits from percentiles.\"\"\"\n",
    "    lo, hi = np.nanpercentile(x, pct[0]), np.nanpercentile(x, pct[1])\n",
    "    if hi <= lo:  # fallback\n",
    "        m, s = np.nanmean(x), np.nanstd(x)\n",
    "        lo, hi = m - 2*s, m + 2*s\n",
    "    return float(lo), float(hi)\n",
    "\n",
    "def show_input_vs_output(\n",
    "    model,\n",
    "    X,\n",
    "    z,\n",
    "    idx=0,\n",
    "    channel_names=None,\n",
    "    stretch=\"asinh\",      # 'asinh' or 'linear'\n",
    "    percentiles=(1, 99),  # for linear scaling\n",
    "    figsize=(12, 6),\n",
    "    cmap=\"gray\",\n",
    "    show_residuals=True,\n",
    "    print_redshift=True):\n",
    "    \"\"\"\n",
    "    Visualize original vs reconstructed image for a single (image, redshift) pair.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : keras.Model\n",
    "        Your trained VAE model with outputs [image_recon, z_recon] or [image_recon].\n",
    "    X : np.ndarray\n",
    "        Image array of shape (N, H, W, C). (C should be 4 for your use case.)\n",
    "    z : np.ndarray\n",
    "        Redshift array of shape (N, 1) or (N,).\n",
    "    idx : int\n",
    "        Index of the sample to visualize.\n",
    "    channel_names : list[str] or None\n",
    "        Optional names for channels (e.g., [\"F115W\",\"F150W\",\"F277W\",\"F444W\"]).\n",
    "    stretch : {'asinh', 'linear'}\n",
    "        Display stretch for visualization.\n",
    "    percentiles : tuple(int,int)\n",
    "        For 'linear' stretch, the (low, high) percentiles to set vmin/vmax.\n",
    "    figsize : tuple\n",
    "        Figure size.\n",
    "    cmap : str\n",
    "        Matplotlib colormap.\n",
    "    show_residuals : bool\n",
    "        If True, shows a third row with (recon - input).\n",
    "    print_redshift : bool\n",
    "        If True, prints the input redshift and predicted redshift (if available).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict with keys:\n",
    "        'x_true', 'x_recon', 'z_true', 'z_pred', 'residual'\n",
    "    \"\"\"\n",
    "\n",
    "    # Prepare the specific sample\n",
    "    x_true = X[idx]\n",
    "    z_true = z[idx]\n",
    "    if z_true.ndim == 0:        # scalar -> (1,)\n",
    "        z_true = np.array([z_true], dtype=np.float32)\n",
    "    if z_true.ndim == 1:        # (1,) -> (1,1) when batching\n",
    "        z_true_b = z_true.reshape(1, 1)\n",
    "    else:\n",
    "        z_true_b = z_true.reshape(1, *z_true.shape)\n",
    "\n",
    "    x_true_b = x_true[np.newaxis, ...]  # (1,H,W,C)\n",
    "\n",
    "    # Forward pass\n",
    "    pred = model.predict([x_true_b, z_true_b], verbose=0)\n",
    "    if isinstance(pred, (list, tuple)):\n",
    "        x_recon_b = pred[0]\n",
    "        z_pred_b = pred[1] if len(pred) > 1 else None\n",
    "    else:\n",
    "        x_recon_b = pred\n",
    "        z_pred_b = None\n",
    "\n",
    "    x_recon = np.squeeze(x_recon_b, axis=0)  # (H,W,C)\n",
    "    residual = x_recon - x_true\n",
    "\n",
    "    # Print redshifts if desired\n",
    "    if print_redshift:\n",
    "        try:\n",
    "            zt_scalar = float(z_true.ravel()[0])\n",
    "        except Exception:\n",
    "            zt_scalar = np.nan\n",
    "        if z_pred_b is not None:\n",
    "            zp_scalar = float(np.squeeze(z_pred_b))\n",
    "            print(f\"z_true = {zt_scalar:.5f} | z_pred = {zp_scalar:.5f}\")\n",
    "        else:\n",
    "            print(f\"z_true = {zt_scalar:.5f} | (model has no z_pred head)\")\n",
    "\n",
    "    H, W, C = x_true.shape\n",
    "    cols = C\n",
    "    rows = 3 if show_residuals else 2\n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=figsize, constrained_layout=True)\n",
    "    if rows == 1:\n",
    "        axes = np.expand_dims(axes, 0)\n",
    "    if cols == 1:\n",
    "        axes = np.expand_dims(axes, 1)\n",
    "\n",
    "    def format_title(base, c):\n",
    "        if channel_names and c < len(channel_names):\n",
    "            return f\"{base} – {channel_names[c]}\"\n",
    "        return f\"{base} – ch{c}\"\n",
    "\n",
    "    for c in range(C):\n",
    "        # Choose scaling for each panel\n",
    "        if stretch == \"asinh\":\n",
    "            a_true = _asinh_stretch(x_true[..., c])\n",
    "            a_reco = _asinh_stretch(x_recon[..., c])\n",
    "            vmin_t, vmax_t = _auto_vmin_vmax(a_true)\n",
    "            vmin_r, vmax_r = _auto_vmin_vmax(a_reco)\n",
    "            # Keep separate vmin/vmax for truth vs recon to show structure clearly\n",
    "            axes[0, c].imshow(a_true, cmap=cmap, vmin=vmin_t, vmax=vmax_t)\n",
    "            axes[1, c].imshow(a_reco, cmap=cmap, vmin=vmin_r, vmax=vmax_r)\n",
    "        else:  # linear\n",
    "            vmin, vmax = _auto_vmin_vmax(x_true[..., c], percentiles)\n",
    "            axes[0, c].imshow(x_true[..., c], cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "            axes[1, c].imshow(x_recon[..., c], cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "\n",
    "        axes[0, c].set_title(format_title(\"Input\", c))\n",
    "        axes[1, c].set_title(format_title(\"Reconstruction\", c))\n",
    "        axes[0, c].axis(\"off\")\n",
    "        axes[1, c].axis(\"off\")\n",
    "\n",
    "        if show_residuals:\n",
    "            # Residuals in linear scale centered at 0 with symmetric range\n",
    "            res = residual[..., c]\n",
    "            m = np.nanmax(np.abs(res)) + 1e-12\n",
    "            axes[2, c].imshow(res, cmap=cmap, vmin=-m, vmax=m)\n",
    "            axes[2, c].set_title(format_title(\"Residual (recon - input)\", c))\n",
    "            axes[2, c].axis(\"off\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return {\n",
    "        \"x_true\": x_true,\n",
    "        \"x_recon\": x_recon,\n",
    "        \"z_true\": z_true,\n",
    "        \"z_pred\": None if z_pred_b is None else float(np.squeeze(z_pred_b)),\n",
    "        \"residual\": residual,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example channel labels for 4-band data:\n",
    "chan_names = [\"F115W\", \"F150W\", \"F277W\", \"F444W\"]\n",
    "\n",
    "# Show sample (change ID as desired)\n",
    "_ = show_input_vs_output(\n",
    "    autoencoder,\n",
    "    X_train,\n",
    "    z_train,\n",
    "    idx=19,\n",
    "    channel_names=chan_names,\n",
    "    stretch=\"linear\",      \n",
    "    show_residuals=True,\n",
    "    cmap=\"gray\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t56oLcBBlDZW"
   },
   "source": [
    "# Visualize the latent space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dlJaJM2wlDZW"
   },
   "source": [
    "Since the latent space is set as 100 per the model architecture, we only select the most distinguishing dimensions to construct pairwise plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LatentSpace_pairplot(encoder_model, images, labels, n_dims=10):\n",
    "    # Encode all images to latent space\n",
    "    z = encoder_model.predict(images, batch_size=64)\n",
    "    \n",
    "    # If latent space > n_dims, only take the first few for clarity\n",
    "    z = z[:, :n_dims]\n",
    "    \n",
    "    # Build a dataframe\n",
    "    df = pd.DataFrame(z, columns=[f\"z{i+1}\" for i in range(n_dims)])\n",
    "    df[\"classification\"] = labels\n",
    "\n",
    "    # color and transparency maps\n",
    "    label_to_color = {\"LRD\": \"red\", \"Galaxy\": \"dodgerblue\", \"AGN\": \"mediumseagreen\"}\n",
    "    label_to_alpha = {\"LRD\": 1.0, \"Galaxy\": 0.15, \"AGN\": 0.45}\n",
    "\n",
    "    # Plot\n",
    "    sns.pairplot(df, hue=\"classification\", palette=label_to_color, plot_kws={'alpha':0.4, 's':20})\n",
    "    plt.suptitle(\"Latent Space Pairplot by Classification\", y=1.02)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract classification labels\n",
    "labels = df_aug[\"classification\"].to_numpy()\n",
    "\n",
    "# Create visualization\n",
    "LatentSpace_pairplot(encoder, [aug_images, aug_redshifts], labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UMAP\n",
    "\n",
    "We use Uniform Manifold Approximation and Projection (UMAP) to reduce the dimensionality of the latent space to a 3D projection while preserving both the global structure (overall shape of the data) and local structure (how nearby points relate to each other)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you don't have umap\n",
    "# !pip install umap-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a known UMAP shadow module in `cuml` which introduces instability and crashes kernels when run on GPU. Run the following block as applicable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect which UMAP package you're actually using\n",
    "import umap\n",
    "print(\"UMAP path:\", umap.__file__)\n",
    "\n",
    "# If the printed path contains \"cuml\" or \"rapids\", then:\n",
    "# !pip uninstall cuml -y\n",
    "# !pip install umap-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer = umap.UMAP(\n",
    "    n_neighbors=15,      # local neighborhood size\n",
    "    min_dist=0.1,        # how tightly UMAP packs points\n",
    "    n_components=3,      # output dimensions (2D or 3D)\n",
    "    metric='euclidean')   # distance metric\n",
    "\n",
    "latent_space = encoder.predict([aug_images, aug_redshifts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create reduced dimension latent space\n",
    "latent_umap = reducer.fit_transform(latent_space)\n",
    "latent_dims = ['UMAP1', 'UMAP2', 'UMAP3']\n",
    "\n",
    "df_latent = pd.DataFrame(latent_umap, columns=latent_dims)\n",
    "df_latent['classification'] = df_aug['classification']\n",
    "\n",
    "# color + alpha mapping to highlight LRDs\n",
    "label_to_color = {\"LRD\": \"red\", \"Galaxy\": \"dodgerblue\", \"AGN\": \"mediumseagreen\"}\n",
    "label_to_alpha = {\"LRD\": 1.0, \"Galaxy\": 0.15, \"AGN\": 0.45}\n",
    "\n",
    "# pairwise plots \n",
    "plot_pairs = [('UMAP1', 'UMAP2'), ('UMAP2', 'UMAP3'), ('UMAP1', 'UMAP3')]\n",
    "\n",
    "for x_dim, y_dim in plot_pairs:\n",
    "    plt.figure(figsize=(9, 7))\n",
    "    \n",
    "    for cls in df_latent['classification'].unique():\n",
    "        subset = df_latent[df_latent['classification'] == cls]\n",
    "        plt.scatter(subset[x_dim], subset[y_dim],\n",
    "                    color=label_to_color[cls],\n",
    "                    alpha=label_to_alpha[cls],\n",
    "                    label=cls,\n",
    "                    s=20)\n",
    "    \n",
    "    plt.xlabel(x_dim)\n",
    "    plt.ylabel(y_dim)\n",
    "    plt.legend()\n",
    "    plt.title(f\"{x_dim} vs {y_dim}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D plot to see latent dimensions at once\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# create figure and 3D axes\n",
    "fig = plt.figure(figsize=(12, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# plot for each classification to maintain different alpha levels\n",
    "for cls in df_latent['classification'].unique():\n",
    "    subset = df_latent[df_latent['classification'] == cls]\n",
    "    ax.scatter(subset['UMAP1'], subset['UMAP2'], subset['UMAP3'],\n",
    "                   c=label_to_color[cls],\n",
    "                   alpha=label_to_alpha[cls],\n",
    "                   label=cls,\n",
    "                   s=20)\n",
    "    \n",
    "ax.set_xlabel('UMAP1')\n",
    "ax.set_ylabel('UMAP2')\n",
    "ax.set_zlabel('UMAP3')\n",
    "ax.legend(title = 'Classification')\n",
    "ax.set_title('3D UMAP of Latent Space')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare latent space distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# Make data frames for separate classes\n",
    "latent_LRD = df_latent[df_latent['classification'] == 'LRD'][['UMAP1','UMAP2','UMAP3']].values\n",
    "latent_Galaxy = df_latent[df_latent['classification'] == 'Galaxy'][['UMAP1','UMAP2','UMAP3']].values\n",
    "latent_AGN = df_latent[df_latent['classification'] == 'AGN'][['UMAP1','UMAP2','UMAP3']].values\n",
    "\n",
    "# Euclidean distances from each LRD to every point in the other groups\n",
    "dist_LRD_Galaxy = cdist(latent_LRD, latent_Galaxy)\n",
    "dist_LRD_AGN = cdist(latent_LRD, latent_AGN)\n",
    "\n",
    "# For each LRD, keep the nearest distance to each group\n",
    "df_LRD = df_latent[df_latent['classification'] == 'LRD'].copy()\n",
    "df_LRD['nearest_galaxy'] = dist_LRD_Galaxy.min(axis=1)\n",
    "df_LRD['nearest_agn'] = dist_LRD_AGN.min(axis=1)\n",
    "\n",
    "# Summary statistics\n",
    "summary_panel = df_LRD[['nearest_galaxy', 'nearest_agn']].describe(percentiles=[.25, .5, .75]).T\n",
    "summary_panel.rename(columns={\n",
    "    '25%': 'Q1',\n",
    "    '50%': 'Median',\n",
    "    '75%': 'Q3'}, inplace=True)\n",
    "summary_panel = summary_panel[['min','Q1','Median','Q3','max','mean','std']]\n",
    "\n",
    "print(summary_panel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*insert conclusions here once I have a model that can be trained for more than 1 epoch*"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
